## Document Upload Processing Module

**`app/core/upload.py`**

```python
"""
Document upload and processing pipeline.

Handles file uploads, text extraction from various formats,
and document indexing with embeddings and full-text search.
"""

from typing import List, Dict, Optional, Tuple
from werkzeug.utils import secure_filename
from werkzeug.datastructures import FileStorage
from sqlalchemy import func
import os
import mimetypes
from pathlib import Path

from app.models import Document, db
from app.core.embeddings import generate_embedding

# Allowed file extensions
ALLOWED_EXTENSIONS = {'txt', 'md', 'pdf', 'docx', 'doc'}

# Maximum file size (10 MB)
MAX_FILE_SIZE = 10 * 1024 * 1024

def allowed_file(filename: str) -> bool:
    """
    Check if file extension is allowed.
    
    Args:
        filename: Name of the uploaded file
        
    Returns:
        True if extension is allowed, False otherwise
    """
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def extract_text_from_txt(file_path: str) -> str:
    """
    Extract text from plain text file.
    
    Args:
        file_path: Path to the text file
        
    Returns:
        Extracted text content
    """
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        return f.read()

def extract_text_from_pdf(file_path: str) -> str:
    """
    Extract text from PDF file using PyPDF2.
    
    Args:
        file_path: Path to the PDF file
        
    Returns:
        Extracted text content
    """
    try:
        import PyPDF2
        
        text = []
        with open(file_path, 'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text.append(page.extract_text())
        
        return '\n\n'.join(text)
    
    except Exception as e:
        raise ValueError(f"Failed to extract text from PDF: {str(e)}")

def extract_text_from_docx(file_path: str) -> str:
    """
    Extract text from Word DOCX file using python-docx.
    
    Args:
        file_path: Path to the DOCX file
        
    Returns:
        Extracted text content
    """
    try:
        import docx
        
        doc = docx.Document(file_path)
        text = []
        
        # Extract text from paragraphs
        for paragraph in doc.paragraphs:
            text.append(paragraph.text)
        
        # Extract text from tables
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    text.append(cell.text)
        
        return '\n\n'.join(text)
    
    except Exception as e:
        raise ValueError(f"Failed to extract text from DOCX: {str(e)}")

def extract_text(file_path: str, file_extension: str) -> str:
    """
    Extract text from uploaded file based on extension.
    
    Args:
        file_path: Path to the uploaded file
        file_extension: File extension (without dot)
        
    Returns:
        Extracted text content
        
    Raises:
        ValueError: If file format is unsupported or extraction fails
    """
    extension = file_extension.lower()
    
    if extension in ['txt', 'md']:
        return extract_text_from_txt(file_path)
    elif extension == 'pdf':
        return extract_text_from_pdf(file_path)
    elif extension in ['docx', 'doc']:
        return extract_text_from_docx(file_path)
    else:
        raise ValueError(f"Unsupported file extension: {extension}")

def generate_ts_vector(text: str) -> str:
    """
    Generate PostgreSQL tsvector for full-text search.
    
    Args:
        text: Document text content
        
    Returns:
        SQL expression for tsvector generation
    """
    # This returns a SQL expression that PostgreSQL will execute
    # The actual tsvector is generated by PostgreSQL
    return func.to_tsvector('english', text)

def infer_category(filename: str, content: str) -> str:
    """
    Infer document category from filename and content.
    
    Args:
        filename: Original filename
        content: Document text content
        
    Returns:
        Category string: 'code_snippets', 'ml_concepts', or 'general_knowledge'
    """
    filename_lower = filename.lower()
    content_lower = content.lower()
    
    # Check for code patterns
    code_indicators = [
        'def ', 'function ', 'class ', 'import ', 'SELECT ', 'FROM ',
        'var ', 'const ', 'let ', 'public ', 'private ', '{', '}'
    ]
    if any(indicator in content for indicator in code_indicators):
        return 'code_snippets'
    
    # Check for ML/AI patterns
    ml_keywords = [
        'neural network', 'machine learning', 'deep learning', 'model',
        'training', 'algorithm', 'gradient', 'backpropagation', 'embedding',
        'transformer', 'attention', 'classification', 'regression'
    ]
    if any(keyword in content_lower for keyword in ml_keywords):
        return 'ml_concepts'
    
    return 'general_knowledge'

def process_uploaded_file(
    file: FileStorage,
    upload_dir: str,
    title: Optional[str] = None,
    category: Optional[str] = None
) -> Document:
    """
    Process uploaded file and store in database.
    
    Args:
        file: Uploaded file from Flask request
        upload_dir: Directory to save uploaded files
        title: Optional custom title (uses filename if not provided)
        category: Optional category (auto-inferred if not provided)
        
    Returns:
        Created Document instance
        
    Raises:
        ValueError: If file is invalid or processing fails
    """
    # Validate file
    if not file or file.filename == '':
        raise ValueError("No file selected")
    
    if not allowed_file(file.filename):
        raise ValueError(f"File type not allowed. Supported: {', '.join(ALLOWED_EXTENSIONS)}")
    
    # Check file size
    file.seek(0, os.SEEK_END)
    file_size = file.tell()
    file.seek(0)
    
    if file_size > MAX_FILE_SIZE:
        raise ValueError(f"File too large. Maximum size: {MAX_FILE_SIZE / 1024 / 1024:.1f} MB")
    
    # Secure filename and save
    filename = secure_filename(file.filename)
    file_extension = filename.rsplit('.', 1)[1].lower()
    
    # Create upload directory if it doesn't exist
    os.makedirs(upload_dir, exist_ok=True)
    
    file_path = os.path.join(upload_dir, filename)
    
    # Handle duplicate filenames
    counter = 1
    base_name = filename.rsplit('.', 1)[0]
    while os.path.exists(file_path):
        filename = f"{base_name}_{counter}.{file_extension}"
        file_path = os.path.join(upload_dir, filename)
        counter += 1
    
    # Save file
    file.save(file_path)
    
    try:
        # Extract text content
        content = extract_text(file_path, file_extension)
        
        if not content or not content.strip():
            raise ValueError("No text content could be extracted from file")
        
        # Use filename as title if not provided
        if not title:
            title = Path(filename).stem.replace('_', ' ').replace('-', ' ').title()
        
        # Infer category if not provided
        if not category:
            category = infer_category(filename, content)
        
        # Generate embedding for semantic search
        embedding = generate_embedding(content)
        
        # Create document with ts_vector for full-text search
        doc = Document(
            title=title,
            content=content,
            file_path=file_path,
            category=category,
            embedding=embedding,
            ts_vector=generate_ts_vector(content)
        )
        
        db.session.add(doc)
        db.session.commit()
        
        return doc
    
    except Exception as e:
        # Clean up file if processing failed
        if os.path.exists(file_path):
            os.remove(file_path)
        raise ValueError(f"Failed to process file: {str(e)}")

def process_batch_upload(
    files: List[FileStorage],
    upload_dir: str
) -> Tuple[List[Document], List[Dict[str, str]]]:
    """
    Process multiple uploaded files in batch.
    
    Args:
        files: List of uploaded files
        upload_dir: Directory to save uploaded files
        
    Returns:
        Tuple of (successful_documents, errors)
        errors format: [{'filename': str, 'error': str}, ...]
    """
    successful = []
    errors = []
    
    for file in files:
        try:
            doc = process_uploaded_file(file, upload_dir)
            successful.append(doc)
        except Exception as e:
            errors.append({
                'filename': file.filename if file else 'unknown',
                'error': str(e)
            })
    
    return successful, errors

def delete_document(doc_id: int) -> bool:
    """
    Delete document and associated file.
    
    Args:
        doc_id: Document ID to delete
        
    Returns:
        True if deleted successfully, False if document not found
    """
    doc = Document.query.get(doc_id)
    
    if not doc:
        return False
    
    # Delete physical file if it exists
    if doc.file_path and os.path.exists(doc.file_path):
        try:
            os.remove(doc.file_path)
        except Exception as e:
            print(f"Warning: Could not delete file {doc.file_path}: {e}")
    
    # Delete database record
    db.session.delete(doc)
    db.session.commit()
    
    return True

def reindex_document(doc_id: int) -> Document:
    """
    Regenerate embedding and ts_vector for a document.
    
    Useful when switching embedding models or updating search indices.
    
    Args:
        doc_id: Document ID to reindex
        
    Returns:
        Updated Document instance
        
    Raises:
        ValueError: If document not found
    """
    doc = Document.query.get(doc_id)
    
    if not doc:
        raise ValueError(f"Document {doc_id} not found")
    
    # Regenerate embedding
    doc.embedding = generate_embedding(doc.content)
    
    # Regenerate ts_vector
    doc.ts_vector = generate_ts_vector(doc.content)
    
    db.session.commit()
    
    return doc

def get_upload_statistics() -> Dict[str, any]:
    """
    Get statistics about uploaded documents.
    
    Returns:
        Dictionary with upload statistics
    """
    total_docs = Document.query.count()
    
    by_category = db.session.query(
        Document.category,
        func.count(Document.id)
    ).group_by(Document.category).all()
    
    return {
        'total_documents': total_docs,
        'by_category': {cat: count for cat, count in by_category},
        'has_embeddings': Document.query.filter(Document.embedding.isnot(None)).count(),
        'has_ts_vector': Document.query.filter(Document.ts_vector.isnot(None)).count()
    }
```

## Integration with Routes

**`app/routes/main.py`** (Upload route example)

```python
from flask import Blueprint, render_template, request, jsonify, current_app
from werkzeug.utils import secure_filename
from app.core.upload import (
    process_uploaded_file,
    process_batch_upload,
    get_upload_statistics,
    allowed_file
)

main_bp = Blueprint('main', __name__)

@main_bp.route('/upload', methods=['GET', 'POST'])
def upload():
    """Handle file uploads."""
    if request.method == 'POST':
        # Check if files were uploaded
        if 'files' not in request.files:
            return jsonify({'error': 'No files uploaded'}), 400
        
        files = request.files.getlist('files')
        
        if not files or all(f.filename == '' for f in files):
            return jsonify({'error': 'No files selected'}), 400
        
        # Get upload directory from app config
        upload_dir = current_app.config.get('UPLOAD_FOLDER', 'uploads')
        
        # Process batch upload
        successful, errors = process_batch_upload(files, upload_dir)
        
        return jsonify({
            'success': len(successful),
            'errors': errors,
            'documents': [
                {
                    'id': doc.id,
                    'title': doc.title,
                    'category': doc.category
                }
                for doc in successful
            ]
        })
    
    # GET request - show upload form
    stats = get_upload_statistics()
    return render_template('search/upload.html', stats=stats)

@main_bp.route('/api/upload/validate', methods=['POST'])
def validate_upload():
    """Validate file before upload."""
    data = request.get_json()
    filename = data.get('filename', '')
    
    if not allowed_file(filename):
        return jsonify({
            'valid': False,
            'error': 'File type not supported'
        })
    
    return jsonify({'valid': True})
```

## Usage Examples

### 1. Single File Upload
```python
from flask import request
from app.core.upload import process_uploaded_file

@app.route('/upload', methods=['POST'])
def upload_file():
    file = request.files['file']
    upload_dir = 'uploads'
    
    try:
        doc = process_uploaded_file(
            file,
            upload_dir,
            title="Custom Title",
            category="code_snippets"
        )
        return jsonify({'success': True, 'doc_id': doc.id})
    except ValueError as e:
        return jsonify({'error': str(e)}), 400
```

### 2. Batch Upload
```python
from app.core.upload import process_batch_upload

files = request.files.getlist('files')
successful, errors = process_batch_upload(files, 'uploads')

print(f"Uploaded {len(successful)} files")
for error in errors:
    print(f"Failed: {error['filename']} - {error['error']}")
```

### 3. Reindex All Documents
```python
from app.models import Document
from app.core.upload import reindex_document

# Reindex all documents (e.g., after model upgrade)
docs = Document.query.all()
for doc in docs:
    try:
        reindex_document(doc.id)
        print(f"Reindexed: {doc.title}")
    except Exception as e:
        print(f"Failed to reindex {doc.id}: {e}")
```

## File Structure

Expected upload directory structure:
```
uploads/
├── document1.pdf
├── document2.txt
├── research_paper.docx
└── code_snippet_1.txt
```

## Configuration

Add to `app/config.py`:
```python
class Config:
    UPLOAD_FOLDER = 'uploads'
    MAX_CONTENT_LENGTH = 10 * 1024 * 1024  # 10 MB
    ALLOWED_EXTENSIONS = {'txt', 'md', 'pdf', 'docx', 'doc'}
```

## Error Handling

The module handles various error cases:
- **Invalid file types**: Checks against ALLOWED_EXTENSIONS
- **File too large**: Enforces MAX_FILE_SIZE limit
- **Empty content**: Validates extracted text is not empty
- **Duplicate filenames**: Auto-renames with counter suffix
- **Extraction failures**: Catches and reports format-specific errors
- **Database failures**: Rolls back and cleans up uploaded file

## Security Considerations

1. **Filename sanitization**: Uses `secure_filename()` to prevent path traversal
2. **File type validation**: Checks extensions and MIME types
3. **Size limits**: Enforces maximum file size
4. **Content validation**: Ensures extracted text is not empty
5. **Error isolation**: Failed uploads don't affect successful ones in batch
